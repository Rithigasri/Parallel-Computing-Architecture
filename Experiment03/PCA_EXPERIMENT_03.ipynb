{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9ivdoOSjx82",
        "outputId": "a573ccc7-e1ab-42c1-fa3a-748612bbf620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-hb7pd9__\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-hb7pd9__\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "directory /content/src already exists\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kernel ReduceUnrolling 8"
      ],
      "metadata": {
        "id": "sMuksTC_kGgs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <sys/time.h>\n",
        "/*\n",
        " * This code implements the interleaved and neighbor-paired approaches to\n",
        " * parallel reduction in CUDA. For this example, the sum operation is used. A\n",
        " * variety of optimizations on parallel reduction aimed at reducing divergence\n",
        " * are also demonstrated, such as unrolling.\n",
        " */\n",
        "\n",
        "// Recursive Implementation of Interleaved Pair Approach\n",
        "int recursiveReduce(int *data, int const size)\n",
        "{\n",
        "    // terminate check\n",
        "    if (size == 1) return data[0];\n",
        "\n",
        "    // renew the stride\n",
        "    int const stride = size / 2;\n",
        "\n",
        "    // in-place reduction\n",
        "    for (int i = 0; i < stride; i++)\n",
        "    {\n",
        "        data[i] += data[i + stride];\n",
        "    }\n",
        "\n",
        "    // call recursively\n",
        "    return recursiveReduce(data, stride);\n",
        "}\n",
        "\n",
        "// Neighbored Pair Implementation with divergence\n",
        "__global__ void reduceNeighbored (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // boundary check\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        if ((tid % (2 * stride)) == 0)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "// Neighbored Pair Implementation with less divergence\n",
        "__global__ void reduceNeighboredLess (int *g_idata, int *g_odata,\n",
        "                                      unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // boundary check\n",
        "    if(idx >= n) return;\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        // convert tid into local array index\n",
        "        int index = 2 * stride * tid;\n",
        "\n",
        "        if (index < blockDim.x)\n",
        "        {\n",
        "            idata[index] += idata[index + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "// Interleaved Pair Implementation with less divergence\n",
        "__global__ void reduceInterleaved (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // boundary check\n",
        "    if(idx >= n) return;\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling2 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
        "\n",
        "    // unrolling 2\n",
        "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling4 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 4;\n",
        "\n",
        "    // unrolling 4\n",
        "    if (idx + 3 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling8 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrollWarps8 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vmem = idata;\n",
        "        vmem[tid] += vmem[tid + 32];\n",
        "        vmem[tid] += vmem[tid + 16];\n",
        "        vmem[tid] += vmem[tid +  8];\n",
        "        vmem[tid] += vmem[tid +  4];\n",
        "        vmem[tid] += vmem[tid +  2];\n",
        "        vmem[tid] += vmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceCompleteUnrollWarps8 (int *g_idata, int *g_odata,\n",
        "        unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction and complete unroll\n",
        "    if (blockDim.x >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 512 && tid < 256) idata[tid] += idata[tid + 256];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 256 && tid < 128) idata[tid] += idata[tid + 128];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 128 && tid < 64) idata[tid] += idata[tid + 64];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "template <unsigned int iBlockSize>\n",
        "__global__ void reduceCompleteUnroll(int *g_idata, int *g_odata,\n",
        "                                     unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction and complete unroll\n",
        "    if (iBlockSize >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 512 && tid < 256)  idata[tid] += idata[tid + 256];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 256 && tid < 128)  idata[tid] += idata[tid + 128];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 128 && tid < 64)   idata[tid] += idata[tid + 64];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrollWarps (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
        "\n",
        "    // unrolling 2\n",
        "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // unrolling last warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "#ifndef _COMMON_H\n",
        "#define _COMMON_H\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUBLAS(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    cublasStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CURAND(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    curandStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUFFT(call)                                                      \\\n",
        "{                                                                              \\\n",
        "    cufftResult err;                                                           \\\n",
        "    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUSPARSE(call)                                                   \\\n",
        "{                                                                              \\\n",
        "    cusparseStatus_t err;                                                      \\\n",
        "    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n",
        "        cudaError_t cuda_err = cudaGetLastError();                             \\\n",
        "        if (cuda_err != cudaSuccess)                                           \\\n",
        "        {                                                                      \\\n",
        "            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n",
        "                    cudaGetErrorString(cuda_err));                             \\\n",
        "        }                                                                      \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "inline double seconds()\n",
        "{\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "#endif // _COMMON_H\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"%s starting reduction at \", argv[0]);\n",
        "    printf(\"device %d: %s \", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    bool bResult = false;\n",
        "\n",
        "    // initialization\n",
        "    int size = 1 << 24; // total number of elements to reduce\n",
        "    printf(\"    with array size %d  \", size);\n",
        "\n",
        "    // execution configuration\n",
        "    int blocksize = 512;   // initial block size\n",
        "\n",
        "    if(argc > 1)\n",
        "    {\n",
        "        blocksize = atoi(argv[1]);   // block size from command line argument\n",
        "    }\n",
        "\n",
        "    dim3 block (blocksize, 1);\n",
        "    dim3 grid  ((size + block.x - 1) / block.x, 1);\n",
        "    printf(\"grid %d block %d\\n\", grid.x, block.x);\n",
        "\n",
        "    // allocate host memory\n",
        "    size_t bytes = size * sizeof(int);\n",
        "    int *h_idata = (int *) malloc(bytes);\n",
        "    int *h_odata = (int *) malloc(grid.x * sizeof(int));\n",
        "    int *tmp     = (int *) malloc(bytes);\n",
        "\n",
        "    // initialize the array\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        // mask off high 2 bytes to force max number to 255\n",
        "        h_idata[i] = (int)( rand() & 0xFF );\n",
        "    }\n",
        "\n",
        "    memcpy (tmp, h_idata, bytes);\n",
        "\n",
        "    double iStart, iElaps;\n",
        "    int gpu_sum = 0;\n",
        "\n",
        "    // allocate device memory\n",
        "    int *d_idata = NULL;\n",
        "    int *d_odata = NULL;\n",
        "    CHECK(cudaMalloc((void **) &d_idata, bytes));\n",
        "    CHECK(cudaMalloc((void **) &d_odata, grid.x * sizeof(int)));\n",
        "\n",
        "    // cpu reduction\n",
        "    iStart = seconds();\n",
        "    int cpu_sum = recursiveReduce (tmp, size);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"cpu reduce      elapsed %f sec cpu_sum: %d\\n\", iElaps, cpu_sum);\n",
        "\n",
        "    // kernel 1: reduceNeighbored\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceNeighbored<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Neighbored  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // kernel 2: reduceNeighbored with less divergence\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceNeighboredLess<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Neighbored2 elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // kernel 3: reduceInterleaved\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceInterleaved<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Interleaved elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // kernel 4: reduceUnrolling2\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling2<<<grid.x / 2, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 2 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 2; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Unrolling2  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 2, block.x);\n",
        "\n",
        "    // kernel 5: reduceUnrolling4\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling4<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Unrolling4  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 4, block.x);\n",
        "\n",
        "    // kernel 6: reduceUnrolling8\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Unrolling8  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "    for (int i = 0; i < grid.x / 16; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    // kernel 8: reduceUnrollWarps8\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu UnrollWarp8 elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "\n",
        "    // kernel 9: reduceCompleteUnrollWarsp8\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceCompleteUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Cmptnroll8  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "    // kernel 9: reduceCompleteUnroll\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "\n",
        "    switch (blocksize)\n",
        "    {\n",
        "    case 1024:\n",
        "        reduceCompleteUnroll<1024><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 512:\n",
        "        reduceCompleteUnroll<512><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 256:\n",
        "        reduceCompleteUnroll<256><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 128:\n",
        "        reduceCompleteUnroll<128><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 64:\n",
        "        reduceCompleteUnroll<64><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "        break;\n",
        "    }\n",
        "\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Cmptnroll   elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "    // free host memory\n",
        "    free(h_idata);\n",
        "    free(h_odata);\n",
        "\n",
        "    // free device memory\n",
        "    CHECK(cudaFree(d_idata));\n",
        "    CHECK(cudaFree(d_odata));\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    // check the results\n",
        "    bResult = (gpu_sum == cpu_sum);\n",
        "\n",
        "    if(!bResult) printf(\"Test failed!\\n\");\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3rUmVE3kIfz",
        "outputId": "8e80fa12-ab5b-43a8-fe43-f1d3c82532df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpag7kvz8f/2560773c-5c29-465f-8a74-b513a83709b6.out starting reduction at device 0: Tesla T4     with array size 16777216  grid 32768 block 512\n",
            "cpu reduce      elapsed 0.077458 sec cpu_sum: 2139353471\n",
            "gpu Neighbored  elapsed 0.003351 sec gpu_sum: 2139353471 <<<grid 32768 block 512>>>\n",
            "gpu Neighbored2 elapsed 0.001856 sec gpu_sum: 2139353471 <<<grid 32768 block 512>>>\n",
            "gpu Interleaved elapsed 0.001672 sec gpu_sum: 2139353471 <<<grid 32768 block 512>>>\n",
            "gpu Unrolling2  elapsed 0.000933 sec gpu_sum: 2139353471 <<<grid 16384 block 512>>>\n",
            "gpu Unrolling4  elapsed 0.000515 sec gpu_sum: 2139353471 <<<grid 8192 block 512>>>\n",
            "gpu Unrolling8  elapsed 0.000322 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "gpu UnrollWarp8 elapsed 0.000363 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "gpu Cmptnroll8  elapsed 0.000355 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "gpu Cmptnroll   elapsed 0.000354 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Kernel ReduceUnrollin16"
      ],
      "metadata": {
        "id": "Tfh_HRKJkitl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda.h>\n",
        "#include <sys/time.h>\n",
        "/*\n",
        " * This code implements the interleaved and neighbor-paired approaches to\n",
        " * parallel reduction in CUDA. For this example, the sum operation is used. A\n",
        " * variety of optimizations on parallel reduction aimed at reducing divergence\n",
        " * are also demonstrated, such as unrolling.\n",
        " */\n",
        "\n",
        "// Recursive Implementation of Interleaved Pair Approach\n",
        "int recursiveReduce(int *data, int const size)\n",
        "{\n",
        "    // terminate check\n",
        "    if (size == 1) return data[0];\n",
        "\n",
        "    // renew the stride\n",
        "    int const stride = size / 2;\n",
        "\n",
        "    // in-place reduction\n",
        "    for (int i = 0; i < stride; i++)\n",
        "    {\n",
        "        data[i] += data[i + stride];\n",
        "    }\n",
        "\n",
        "    // call recursively\n",
        "    return recursiveReduce(data, stride);\n",
        "}\n",
        "\n",
        "// Neighbored Pair Implementation with divergence\n",
        "__global__ void reduceNeighbored (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // boundary check\n",
        "    if (idx >= n) return;\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        if ((tid % (2 * stride)) == 0)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "// Neighbored Pair Implementation with less divergence\n",
        "__global__ void reduceNeighboredLess (int *g_idata, int *g_odata,\n",
        "                                      unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // boundary check\n",
        "    if(idx >= n) return;\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = 1; stride < blockDim.x; stride *= 2)\n",
        "    {\n",
        "        // convert tid into local array index\n",
        "        int index = 2 * stride * tid;\n",
        "\n",
        "        if (index < blockDim.x)\n",
        "        {\n",
        "            idata[index] += idata[index + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "// Interleaved Pair Implementation with less divergence\n",
        "__global__ void reduceInterleaved (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // boundary check\n",
        "    if(idx >= n) return;\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling2 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
        "\n",
        "    // unrolling 2\n",
        "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling4 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 4 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 4;\n",
        "\n",
        "    // unrolling 4\n",
        "    if (idx + 3 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrolling8 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "__global__ void reduceUnrolling16 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 16 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 16;\n",
        "\n",
        "    // unrolling 16\n",
        "    if (idx + 15 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        int c1 = g_idata[idx + 8 * blockDim.x];\n",
        "        int c2 = g_idata[idx + 9 * blockDim.x];\n",
        "        int c3 = g_idata[idx + 10 * blockDim.x];\n",
        "        int c4 = g_idata[idx + 11 * blockDim.x];\n",
        "        int d1 = g_idata[idx + 12 * blockDim.x];\n",
        "        int d2 = g_idata[idx + 13 * blockDim.x];\n",
        "        int d3 = g_idata[idx + 14 * blockDim.x];\n",
        "        int d4 = g_idata[idx + 15 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4 + c1 + c2 + c3 + c4\n",
        "                       + d1 + d2 + d3 + d4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 0; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrollWarps8 (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vmem = idata;\n",
        "        vmem[tid] += vmem[tid + 32];\n",
        "        vmem[tid] += vmem[tid + 16];\n",
        "        vmem[tid] += vmem[tid +  8];\n",
        "        vmem[tid] += vmem[tid +  4];\n",
        "        vmem[tid] += vmem[tid +  2];\n",
        "        vmem[tid] += vmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceCompleteUnrollWarps8 (int *g_idata, int *g_odata,\n",
        "        unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction and complete unroll\n",
        "    if (blockDim.x >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 512 && tid < 256) idata[tid] += idata[tid + 256];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 256 && tid < 128) idata[tid] += idata[tid + 128];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (blockDim.x >= 128 && tid < 64) idata[tid] += idata[tid + 64];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "template <unsigned int iBlockSize>\n",
        "__global__ void reduceCompleteUnroll(int *g_idata, int *g_odata,\n",
        "                                     unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 8 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 8;\n",
        "\n",
        "    // unrolling 8\n",
        "    if (idx + 7 * blockDim.x < n)\n",
        "    {\n",
        "        int a1 = g_idata[idx];\n",
        "        int a2 = g_idata[idx + blockDim.x];\n",
        "        int a3 = g_idata[idx + 2 * blockDim.x];\n",
        "        int a4 = g_idata[idx + 3 * blockDim.x];\n",
        "        int b1 = g_idata[idx + 4 * blockDim.x];\n",
        "        int b2 = g_idata[idx + 5 * blockDim.x];\n",
        "        int b3 = g_idata[idx + 6 * blockDim.x];\n",
        "        int b4 = g_idata[idx + 7 * blockDim.x];\n",
        "        g_idata[idx] = a1 + a2 + a3 + a4 + b1 + b2 + b3 + b4;\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction and complete unroll\n",
        "    if (iBlockSize >= 1024 && tid < 512) idata[tid] += idata[tid + 512];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 512 && tid < 256)  idata[tid] += idata[tid + 256];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 256 && tid < 128)  idata[tid] += idata[tid + 128];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (iBlockSize >= 128 && tid < 64)   idata[tid] += idata[tid + 64];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // unrolling warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    // write result for this block to global mem\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "\n",
        "__global__ void reduceUnrollWarps (int *g_idata, int *g_odata, unsigned int n)\n",
        "{\n",
        "    // set thread ID\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int idx = blockIdx.x * blockDim.x * 2 + threadIdx.x;\n",
        "\n",
        "    // convert global data pointer to the local pointer of this block\n",
        "    int *idata = g_idata + blockIdx.x * blockDim.x * 2;\n",
        "\n",
        "    // unrolling 2\n",
        "    if (idx + blockDim.x < n) g_idata[idx] += g_idata[idx + blockDim.x];\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    // in-place reduction in global memory\n",
        "    for (int stride = blockDim.x / 2; stride > 32; stride >>= 1)\n",
        "    {\n",
        "        if (tid < stride)\n",
        "        {\n",
        "            idata[tid] += idata[tid + stride];\n",
        "        }\n",
        "\n",
        "        // synchronize within threadblock\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // unrolling last warp\n",
        "    if (tid < 32)\n",
        "    {\n",
        "        volatile int *vsmem = idata;\n",
        "        vsmem[tid] += vsmem[tid + 32];\n",
        "        vsmem[tid] += vsmem[tid + 16];\n",
        "        vsmem[tid] += vsmem[tid +  8];\n",
        "        vsmem[tid] += vsmem[tid +  4];\n",
        "        vsmem[tid] += vsmem[tid +  2];\n",
        "        vsmem[tid] += vsmem[tid +  1];\n",
        "    }\n",
        "\n",
        "    if (tid == 0) g_odata[blockIdx.x] = idata[0];\n",
        "}\n",
        "#ifndef _COMMON_H\n",
        "#define _COMMON_H\n",
        "\n",
        "#define CHECK(call)                                                            \\\n",
        "{                                                                              \\\n",
        "    const cudaError_t error = call;                                            \\\n",
        "    if (error != cudaSuccess)                                                  \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Error: %s:%d, \", __FILE__, __LINE__);                 \\\n",
        "        fprintf(stderr, \"code: %d, reason: %s\\n\", error,                       \\\n",
        "                cudaGetErrorString(error));                                    \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUBLAS(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    cublasStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CUBLAS_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUBLAS error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CURAND(call)                                                     \\\n",
        "{                                                                              \\\n",
        "    curandStatus_t err;                                                        \\\n",
        "    if ((err = (call)) != CURAND_STATUS_SUCCESS)                               \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CURAND error %d at %s:%d\\n\", err, __FILE__,       \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUFFT(call)                                                      \\\n",
        "{                                                                              \\\n",
        "    cufftResult err;                                                           \\\n",
        "    if ( (err = (call)) != CUFFT_SUCCESS)                                      \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got CUFFT error %d at %s:%d\\n\", err, __FILE__,        \\\n",
        "                __LINE__);                                                     \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "#define CHECK_CUSPARSE(call)                                                   \\\n",
        "{                                                                              \\\n",
        "    cusparseStatus_t err;                                                      \\\n",
        "    if ((err = (call)) != CUSPARSE_STATUS_SUCCESS)                             \\\n",
        "    {                                                                          \\\n",
        "        fprintf(stderr, \"Got error %d at %s:%d\\n\", err, __FILE__, __LINE__);   \\\n",
        "        cudaError_t cuda_err = cudaGetLastError();                             \\\n",
        "        if (cuda_err != cudaSuccess)                                           \\\n",
        "        {                                                                      \\\n",
        "            fprintf(stderr, \"  CUDA error \\\"%s\\\" also detected\\n\",             \\\n",
        "                    cudaGetErrorString(cuda_err));                             \\\n",
        "        }                                                                      \\\n",
        "        exit(1);                                                               \\\n",
        "    }                                                                          \\\n",
        "}\n",
        "\n",
        "inline double seconds()\n",
        "{\n",
        "    struct timeval tp;\n",
        "    struct timezone tzp;\n",
        "    int i = gettimeofday(&tp, &tzp);\n",
        "    return ((double)tp.tv_sec + (double)tp.tv_usec * 1.e-6);\n",
        "}\n",
        "\n",
        "#endif // _COMMON_H\n",
        "\n",
        "int main(int argc, char **argv)\n",
        "{\n",
        "    // set up device\n",
        "    int dev = 0;\n",
        "    cudaDeviceProp deviceProp;\n",
        "    CHECK(cudaGetDeviceProperties(&deviceProp, dev));\n",
        "    printf(\"%s starting reduction at \", argv[0]);\n",
        "    printf(\"device %d: %s \", dev, deviceProp.name);\n",
        "    CHECK(cudaSetDevice(dev));\n",
        "\n",
        "    bool bResult = false;\n",
        "\n",
        "    // initialization\n",
        "    int size = 1 << 24; // total number of elements to reduce\n",
        "    printf(\"    with array size %d  \", size);\n",
        "\n",
        "    // execution configuration\n",
        "    int blocksize = 512;   // initial block size\n",
        "\n",
        "    if(argc > 1)\n",
        "    {\n",
        "        blocksize = atoi(argv[1]);   // block size from command line argument\n",
        "    }\n",
        "\n",
        "    dim3 block (blocksize, 1);\n",
        "    dim3 grid  ((size + block.x - 1) / block.x, 1);\n",
        "    printf(\"grid %d block %d\\n\", grid.x, block.x);\n",
        "\n",
        "    // allocate host memory\n",
        "    size_t bytes = size * sizeof(int);\n",
        "    int *h_idata = (int *) malloc(bytes);\n",
        "    int *h_odata = (int *) malloc(grid.x * sizeof(int));\n",
        "    int *tmp     = (int *) malloc(bytes);\n",
        "\n",
        "    // initialize the array\n",
        "    for (int i = 0; i < size; i++)\n",
        "    {\n",
        "        // mask off high 2 bytes to force max number to 255\n",
        "        h_idata[i] = (int)( rand() & 0xFF );\n",
        "    }\n",
        "\n",
        "    memcpy (tmp, h_idata, bytes);\n",
        "\n",
        "    double iStart, iElaps;\n",
        "    int gpu_sum = 0;\n",
        "\n",
        "    // allocate device memory\n",
        "    int *d_idata = NULL;\n",
        "    int *d_odata = NULL;\n",
        "    CHECK(cudaMalloc((void **) &d_idata, bytes));\n",
        "    CHECK(cudaMalloc((void **) &d_odata, grid.x * sizeof(int)));\n",
        "\n",
        "    // cpu reduction\n",
        "    iStart = seconds();\n",
        "    int cpu_sum = recursiveReduce (tmp, size);\n",
        "    iElaps = seconds() - iStart;\n",
        "    printf(\"cpu reduce      elapsed %f sec cpu_sum: %d\\n\", iElaps, cpu_sum);\n",
        "\n",
        "    // kernel 1: reduceNeighbored\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceNeighbored<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Neighbored  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // kernel 2: reduceNeighbored with less divergence\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceNeighboredLess<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Neighbored2 elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // kernel 3: reduceInterleaved\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceInterleaved<<<grid, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Interleaved elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x, block.x);\n",
        "\n",
        "    // kernel 4: reduceUnrolling2\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling2<<<grid.x / 2, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 2 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 2; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Unrolling2  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 2, block.x);\n",
        "\n",
        "    // kernel 5: reduceUnrolling4\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling4<<<grid.x / 4, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 4 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 4; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Unrolling4  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 4, block.x);\n",
        "\n",
        "    // kernel 6: reduceUnrolling8\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Unrolling8  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "    for (int i = 0; i < grid.x / 16; i++) gpu_sum += h_odata[i];\n",
        "// kernel 7: reduceUnrolling16\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrolling16<<<grid.x / 16, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 16 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 16; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Unrolling16 elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 16, block.x);\n",
        "\n",
        "    // kernel 8: reduceUnrollWarps8\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu UnrollWarp8 elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "\n",
        "    // kernel 9: reduceCompleteUnrollWarsp8\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "    reduceCompleteUnrollWarps8<<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Cmptnroll8  elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "    // kernel 9: reduceCompleteUnroll\n",
        "    CHECK(cudaMemcpy(d_idata, h_idata, bytes, cudaMemcpyHostToDevice));\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iStart = seconds();\n",
        "\n",
        "    switch (blocksize)\n",
        "    {\n",
        "    case 1024:\n",
        "        reduceCompleteUnroll<1024><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 512:\n",
        "        reduceCompleteUnroll<512><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 256:\n",
        "        reduceCompleteUnroll<256><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 128:\n",
        "        reduceCompleteUnroll<128><<<grid.x / 8, block>>>(d_idata, d_odata,\n",
        "                size);\n",
        "        break;\n",
        "\n",
        "    case 64:\n",
        "        reduceCompleteUnroll<64><<<grid.x / 8, block>>>(d_idata, d_odata, size);\n",
        "        break;\n",
        "    }\n",
        "\n",
        "    CHECK(cudaDeviceSynchronize());\n",
        "    iElaps = seconds() - iStart;\n",
        "    CHECK(cudaMemcpy(h_odata, d_odata, grid.x / 8 * sizeof(int),\n",
        "                     cudaMemcpyDeviceToHost));\n",
        "\n",
        "    gpu_sum = 0;\n",
        "\n",
        "    for (int i = 0; i < grid.x / 8; i++) gpu_sum += h_odata[i];\n",
        "\n",
        "    printf(\"gpu Cmptnroll   elapsed %f sec gpu_sum: %d <<<grid %d block \"\n",
        "           \"%d>>>\\n\", iElaps, gpu_sum, grid.x / 8, block.x);\n",
        "\n",
        "    // free host memory\n",
        "    free(h_idata);\n",
        "    free(h_odata);\n",
        "\n",
        "    // free device memory\n",
        "    CHECK(cudaFree(d_idata));\n",
        "    CHECK(cudaFree(d_odata));\n",
        "\n",
        "    // reset device\n",
        "    CHECK(cudaDeviceReset());\n",
        "\n",
        "    // check the results\n",
        "    bResult = (gpu_sum == cpu_sum);\n",
        "\n",
        "    if(!bResult) printf(\"Test failed!\\n\");\n",
        "\n",
        "    return EXIT_SUCCESS;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvdmdh1Uty5S",
        "outputId": "81d88cd5-e06a-4f69-e3ee-6e784847f514"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/tmp/tmpvwuy0mlw/b59a9199-83f6-4e5c-a115-699d9bf0e356.out starting reduction at device 0: Tesla T4     with array size 16777216  grid 32768 block 512\n",
            "cpu reduce      elapsed 0.078468 sec cpu_sum: 2139353471\n",
            "gpu Neighbored  elapsed 0.003362 sec gpu_sum: 2139353471 <<<grid 32768 block 512>>>\n",
            "gpu Neighbored2 elapsed 0.001852 sec gpu_sum: 2139353471 <<<grid 32768 block 512>>>\n",
            "gpu Interleaved elapsed 0.001667 sec gpu_sum: 2139353471 <<<grid 32768 block 512>>>\n",
            "gpu Unrolling2  elapsed 0.000945 sec gpu_sum: 2139353471 <<<grid 16384 block 512>>>\n",
            "gpu Unrolling4  elapsed 0.000513 sec gpu_sum: 2139353471 <<<grid 8192 block 512>>>\n",
            "gpu Unrolling8  elapsed 0.000320 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "gpu Unrolling16 elapsed 0.000301 sec gpu_sum: 2139353471 <<<grid 2048 block 512>>>\n",
            "gpu UnrollWarp8 elapsed 0.000363 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "gpu Cmptnroll8  elapsed 0.000359 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "gpu Cmptnroll   elapsed 0.000354 sec gpu_sum: 2139353471 <<<grid 4096 block 512>>>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "supvJAZtv40_"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}